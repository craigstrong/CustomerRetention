{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, roc_curve, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139616, 45)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datafiles/CO_2014_2015.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age', 'CustomerLifetimeSpend',\n",
    "       #'Customer1YearSpend', \n",
    "       'Customer3YearSpend', 'ThreeYearVisitCount',\n",
    "       'SkiLoyaltyIndexRating', 'FrontRangeMarket',\n",
    "       'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012',\n",
    "       'Spend_Winter_2013', 'Spend_Winter_2014', #'Spend_Winter_2015',\n",
    "       #'Household1YearSpend',\n",
    "       'Household3YearSpend', 'HouseholdLifetimeSpend',\n",
    "       'NumberOfHouseholdMembers', 'NumberOfAdults',\n",
    "       'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011',\n",
    "       'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014',\n",
    "       'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015',\n",
    "       'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15',\n",
    "       'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', \n",
    "       'Ski_Resort1_2014_2015',\n",
    "       'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "y = df['Pass_Winter_2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline for Previous Pass Customers purchasing a 2015/2016 Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4682128122851249"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test, Split of X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46732943693177476"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47086293834517534"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the data for some of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "# Fit Scaler on X_train data from TTS\n",
    "ss.fit(X_train)\n",
    "# Transform X_Train data from TTS\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "#Transform X_test from TTS\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of Classification Models based on Non-Scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed KNN and SVC because they took a long time and did not score well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('knn_class', KNeighborsClassifier()),\n",
    "#('svc', SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Score: 0.7341565629431587\n",
      "Testing Score: 0.7310050424020169 \n",
      "\n",
      "F1 Score: 0.6818043176195479 \n",
      "\n",
      "Decision Tree Classifier\n",
      "Training Score: 0.7996600676350268\n",
      "Testing Score: 0.806268622507449 \n",
      "\n",
      "F1 Score: 0.7939042974702835 \n",
      "\n",
      "Bagging Classifier\n",
      "Training Score: 0.8418042093437199\n",
      "Testing Score: 0.8472381388952556 \n",
      "\n",
      "F1 Score: 0.8355336212214682 \n",
      "\n",
      "Random Forest Classifier\n",
      "Training Score: 0.8401234234458088\n",
      "Testing Score: 0.8453758881503552 \n",
      "\n",
      "F1 Score: 0.8331633126217194 \n",
      "\n",
      "AdaBoost Classifier\n",
      "Training Score: 0.7648980222472964\n",
      "Testing Score: 0.7616032546413019 \n",
      "\n",
      "F1 Score: 0.747350842568696 \n",
      "\n",
      "XGBoost Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8126766801662845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score: 0.81199862479945 \n",
      "\n",
      "F1 Score: 0.8061333018199007 \n",
      "\n",
      "Neural Net Classifier\n",
      "Training Score: 0.6380349519888542\n",
      "Testing Score: 0.7426369470547788 \n",
      "\n",
      "F1 Score: 0.7571571463328919 \n",
      "\n",
      "CPU times: user 3min 4s, sys: 7.1 s, total: 3min 11s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimators = [\n",
    "              ('Logistic Regression', LogisticRegression()),\n",
    "              ('Decision Tree Classifier', DecisionTreeClassifier()),  \n",
    "              ('Bagging Classifier', BaggingClassifier()),\n",
    "              ('Random Forest Classifier', RandomForestClassifier()),\n",
    "              ('AdaBoost Classifier', AdaBoostClassifier()),\n",
    "              ('XGBoost Classifier', XGBClassifier()),\n",
    "              ('Neural Net Classifier', MLPClassifier(alpha=1))\n",
    "             ]\n",
    "for estimator in estimators:\n",
    "    pipe = Pipeline([estimator])\n",
    "    print(estimator[0])\n",
    "    print('Training Score: {}'.format(cross_val_score(pipe, X_train, y_train).mean()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    print('Testing Score: {}'.format(pipe.score(X_test, y_test)), '\\n')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, y_hat)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of Classification Models based on Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Score: 0.7336504162971677\n",
      "Testing Score: 0.731692642677057 \n",
      "\n",
      "F1 Score: 0.698146435961784 \n",
      "\n",
      "Decision Tree Classifier\n",
      "Training Score: 0.7982084659590307\n",
      "Testing Score: 0.8067270226908091 \n",
      "\n",
      "F1 Score: 0.4351331360946746 \n",
      "\n",
      "Bagging Classifier\n",
      "Training Score: 0.8424440516657965\n",
      "Testing Score: 0.8478111391244556 \n",
      "\n",
      "F1 Score: 0.5244267918396822 \n",
      "\n",
      "Random Forest Classifier\n",
      "Training Score: 0.8410497948843393\n",
      "Testing Score: 0.8470662388264956 \n",
      "\n",
      "F1 Score: 0.6307729352275464 \n",
      "\n",
      "AdaBoost Classifier\n",
      "Training Score: 0.7648980222472964\n",
      "Testing Score: 0.7616032546413019 \n",
      "\n",
      "F1 Score: 0.6633970295655393 \n",
      "\n",
      "Neural Net Classifier\n",
      "Training Score: 0.8081022630817288\n",
      "Testing Score: 0.8046642218656888 \n",
      "\n",
      "F1 Score: 0.5192059283431912 \n",
      "\n",
      "XGBoost Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8126766801662845\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37'] ['Age', 'CustomerLifetimeSpend', 'Customer3YearSpend', 'ThreeYearVisitCount', 'SkiLoyaltyIndexRating', 'FrontRangeMarket', 'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012', 'Spend_Winter_2013', 'Spend_Winter_2014', 'Household3YearSpend', 'HouseholdLifetimeSpend', 'NumberOfHouseholdMembers', 'NumberOfAdults', 'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011', 'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014', 'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015', 'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15', 'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', 'Ski_Resort1_2014_2015', 'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']\nexpected f8, f7, f21, f16, f4, f6, f26, f28, f5, f3, f12, f14, f15, f37, f13, f20, f36, f25, f34, f23, f22, f17, f11, f24, f31, f35, f1, f9, f10, f30, f2, f0, f32, f29, f27, f33, f19, f18 in input data\ntraining data did not have the following fields: SkiLoyaltyIndexRating, Total_Days_14_15, Spend_Winter_2010, Ski_Resort3_2014_2015, April_15, February_15, Age, Regular_Purchase_2014_2015, Pass_Winter_2012, Customer3YearSpend, Pass_Winter_2014, Pass_Winter_2010, FrontRangeMarket, Ski_Resort2_2014_2015, ThreeYearVisitCount, Ski_Resort5_2014_2015, Household3YearSpend, Late_Purchase_2014_2015, Total_Days_13_14, NumberOfHouseholdMembers, Spend_Winter_2014, Pass_Winter_2013, Ski_Resort4_2014_2015, November_14, Ski_Resort1_2014_2015, NumberOfChildren, Spend_Winter_2012, December_14, Spend_Winter_2011, Spend_Winter_2013, NumberOfAdults, March_15, Super_Late_Purchase_2014_2015, January_15, CustomerLifetimeSpend, Pass_Winter_2011, HouseholdLifetimeSpend, Early_Purchase_2014_2015",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    600\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    601\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0mcolumn_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1477\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37'] ['Age', 'CustomerLifetimeSpend', 'Customer3YearSpend', 'ThreeYearVisitCount', 'SkiLoyaltyIndexRating', 'FrontRangeMarket', 'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012', 'Spend_Winter_2013', 'Spend_Winter_2014', 'Household3YearSpend', 'HouseholdLifetimeSpend', 'NumberOfHouseholdMembers', 'NumberOfAdults', 'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011', 'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014', 'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015', 'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15', 'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', 'Ski_Resort1_2014_2015', 'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']\nexpected f8, f7, f21, f16, f4, f6, f26, f28, f5, f3, f12, f14, f15, f37, f13, f20, f36, f25, f34, f23, f22, f17, f11, f24, f31, f35, f1, f9, f10, f30, f2, f0, f32, f29, f27, f33, f19, f18 in input data\ntraining data did not have the following fields: SkiLoyaltyIndexRating, Total_Days_14_15, Spend_Winter_2010, Ski_Resort3_2014_2015, April_15, February_15, Age, Regular_Purchase_2014_2015, Pass_Winter_2012, Customer3YearSpend, Pass_Winter_2014, Pass_Winter_2010, FrontRangeMarket, Ski_Resort2_2014_2015, ThreeYearVisitCount, Ski_Resort5_2014_2015, Household3YearSpend, Late_Purchase_2014_2015, Total_Days_13_14, NumberOfHouseholdMembers, Spend_Winter_2014, Pass_Winter_2013, Ski_Resort4_2014_2015, November_14, Ski_Resort1_2014_2015, NumberOfChildren, Spend_Winter_2012, December_14, Spend_Winter_2011, Spend_Winter_2013, NumberOfAdults, March_15, Super_Late_Purchase_2014_2015, January_15, CustomerLifetimeSpend, Pass_Winter_2011, HouseholdLifetimeSpend, Early_Purchase_2014_2015"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimators = [\n",
    "              ('Logistic Regression', LogisticRegression()),\n",
    "              ('Decision Tree Classifier', DecisionTreeClassifier()),  \n",
    "              ('Bagging Classifier', BaggingClassifier()),\n",
    "              ('Random Forest Classifier', RandomForestClassifier()),\n",
    "              ('AdaBoost Classifier', AdaBoostClassifier()),\n",
    "              ('Neural Net Classifier', MLPClassifier(alpha=1)),\n",
    "              ('XGBoost Classifier', XGBClassifier())              \n",
    "             ]\n",
    "\n",
    "for estimator in estimators:\n",
    "    pipe = Pipeline([estimator])\n",
    "    print(estimator[0])\n",
    "    print('Training Score: {}'.format(cross_val_score(pipe, X_train_scaled, y_train).mean()))\n",
    "    pipe.fit(X_train_scaled, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    print('Testing Score: {}'.format(pipe.score(X_test_scaled, y_test)), '\\n')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, y_hat)), '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
