{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, roc_curve, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>StateProvinceCode</th>\n",
       "      <th>CustomerLifetimeSpend</th>\n",
       "      <th>Customer1YearSpend</th>\n",
       "      <th>Customer3YearSpend</th>\n",
       "      <th>ThreeYearVisitCount</th>\n",
       "      <th>SkiLoyaltyIndexRating</th>\n",
       "      <th>FrontRangeMarket</th>\n",
       "      <th>CustId</th>\n",
       "      <th>Spend_Winter_2010</th>\n",
       "      <th>...</th>\n",
       "      <th>April_15</th>\n",
       "      <th>November_14</th>\n",
       "      <th>December_14</th>\n",
       "      <th>Total_Days_14_15</th>\n",
       "      <th>Total_Days_13_14</th>\n",
       "      <th>Ski_Resort1_2014_2015</th>\n",
       "      <th>Ski_Resort2_2014_2015</th>\n",
       "      <th>Ski_Resort3_2014_2015</th>\n",
       "      <th>Ski_Resort4_2014_2015</th>\n",
       "      <th>Ski_Resort5_2014_2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>CO</td>\n",
       "      <td>55.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.43</td>\n",
       "      <td>19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1073873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>CO</td>\n",
       "      <td>139.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.00</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1073874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>CO</td>\n",
       "      <td>428.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1073876</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>CO</td>\n",
       "      <td>449.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>CO</td>\n",
       "      <td>148.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1073956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age StateProvinceCode  CustomerLifetimeSpend  Customer1YearSpend  \\\n",
       "0   42                CO                  55.61                 0.0   \n",
       "1   48                CO                 139.00                 0.0   \n",
       "2   48                CO                 428.00                 0.0   \n",
       "3   33                CO                 449.00                 0.0   \n",
       "4   24                CO                 148.19                 0.0   \n",
       "\n",
       "   Customer3YearSpend  ThreeYearVisitCount  SkiLoyaltyIndexRating  \\\n",
       "0               42.43                   19                   10.0   \n",
       "1              139.00                   24                    0.0   \n",
       "2                0.00                   13                    0.0   \n",
       "3                0.00                    0                    0.0   \n",
       "4              148.19                    2                    0.0   \n",
       "\n",
       "   FrontRangeMarket   CustId  Spend_Winter_2010          ...            \\\n",
       "0                 1  1073873                0.0          ...             \n",
       "1                 1  1073874                0.0          ...             \n",
       "2                 1  1073876               59.0          ...             \n",
       "3                 0  1073942                0.0          ...             \n",
       "4                 1  1073956                0.0          ...             \n",
       "\n",
       "   April_15  November_14  December_14  Total_Days_14_15  Total_Days_13_14  \\\n",
       "0         0            0            1                 7                 0   \n",
       "1         0            0            0                 2                 2   \n",
       "2         0            0            0                 2                 4   \n",
       "3         0            0            0                 0                 0   \n",
       "4         0            1            0                 4                 0   \n",
       "\n",
       "   Ski_Resort1_2014_2015  Ski_Resort2_2014_2015  Ski_Resort3_2014_2015  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      2   \n",
       "2                      0                      0                      1   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   Ski_Resort4_2014_2015  Ski_Resort5_2014_2015  \n",
       "0                      0                      7  \n",
       "1                      0                      0  \n",
       "2                      0                      1  \n",
       "3                      0                      0  \n",
       "4                      0                      4  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CO_2014_2015.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age', 'CustomerLifetimeSpend',\n",
    "       #'Customer1YearSpend', \n",
    "       'Customer3YearSpend', 'ThreeYearVisitCount',\n",
    "       'SkiLoyaltyIndexRating', 'FrontRangeMarket',\n",
    "       'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012',\n",
    "       'Spend_Winter_2013', 'Spend_Winter_2014', #'Spend_Winter_2015',\n",
    "       #'Household1YearSpend',\n",
    "       'Household3YearSpend', 'HouseholdLifetimeSpend',\n",
    "       'NumberOfHouseholdMembers', 'NumberOfAdults',\n",
    "       'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011',\n",
    "       'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014',\n",
    "       'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015',\n",
    "       'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15',\n",
    "       'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', \n",
    "       'Ski_Resort1_2014_2015',\n",
    "       'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ThreeYearVisitCount', 'Customer3YearSpend', 'Age', 'Total_Days_14_15', 'Pass_Winter_2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Customer3YearSpend', 'Total_Days_14_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols]#.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols]\n",
    "y = df['Pass_Winter_2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 567 µs, sys: 220 µs, total: 787 µs\n",
      "Wall time: 409 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4682128122851249"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46732943693177476"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47086293834517534"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "# Fit Scaler on X_train data from TTS\n",
    "ss.fit(X_train)\n",
    "# Transform X_Train data from TTS\n",
    "X_train_s = ss.transform(X_train)\n",
    "#Transform X_test from TTS\n",
    "X_test_s = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Scaled Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed KNN and SVC because they took a long time and did not score well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('knn_class', KNeighborsClassifier()),\n",
    "('svc', SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg\n",
      "Training Score: 0.7341565629431587\n",
      "Testing Score: 0.7310050424020169 \n",
      "\n",
      "F1 Score: 0.6818043176195479 \n",
      "\n",
      "dt_class\n",
      "Training Score: 0.7987050552133463\n",
      "Testing Score: 0.8073573229429292 \n",
      "\n",
      "F1 Score: 0.7952372251659662 \n",
      "\n",
      "bag_class\n",
      "Training Score: 0.8406009031163947\n",
      "Testing Score: 0.849931239972496 \n",
      "\n",
      "F1 Score: 0.8387315270935961 \n",
      "\n",
      "rf_class\n",
      "Training Score: 0.8393403075364034\n",
      "Testing Score: 0.8462067384826953 \n",
      "\n",
      "F1 Score: 0.8340443949792865 \n",
      "\n",
      "ada_class\n",
      "Training Score: 0.7648980222472964\n",
      "Testing Score: 0.7616032546413019 \n",
      "\n",
      "F1 Score: 0.747350842568696 \n",
      "\n",
      "xg_class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8126766801662845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score: 0.81199862479945 \n",
      "\n",
      "F1 Score: 0.8061333018199007 \n",
      "\n",
      "neural_net\n",
      "Training Score: 0.6922507587262171\n",
      "Testing Score: 0.7433531973412789 \n",
      "\n",
      "F1 Score: 0.7307807898058545 \n",
      "\n",
      "CPU times: user 3min 1s, sys: 7.61 s, total: 3min 8s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimators = [\n",
    "              ('log_reg', LogisticRegression()),\n",
    "              ('dt_class', DecisionTreeClassifier()),  \n",
    "              ('bag_class', BaggingClassifier()),\n",
    "              ('rf_class', RandomForestClassifier()),\n",
    "              ('ada_class', AdaBoostClassifier()),\n",
    "              ('xg_class', XGBClassifier()),\n",
    "              ('neural_net', MLPClassifier(alpha=1))\n",
    "             ]\n",
    "\n",
    "for estimator in estimators:\n",
    "    pipe = Pipeline([estimator])\n",
    "    print(estimator[0])\n",
    "    print('Training Score: {}'.format(cross_val_score(pipe, X_train, y_train).mean()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    print('Testing Score: {}'.format(pipe.score(X_test, y_test)), '\\n')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, y_hat)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg\n",
      "Training Score: 0.7336504162971677\n",
      "Testing Score: 0.731692642677057 \n",
      "\n",
      "F1 Score: 0.698146435961784 \n",
      "\n",
      "dt_class\n",
      "Training Score: 0.7983994457883967\n",
      "Testing Score: 0.806325922530369 \n",
      "\n",
      "F1 Score: 0.5150640263578002 \n",
      "\n",
      "bag_class\n",
      "Training Score: 0.8408778586985451\n",
      "Testing Score: 0.849902589961036 \n",
      "\n",
      "F1 Score: 0.6148132539640732 \n",
      "\n",
      "rf_class\n",
      "Training Score: 0.8397223090576419\n",
      "Testing Score: 0.8489284895713959 \n",
      "\n",
      "F1 Score: 0.5862504739037028 \n",
      "\n",
      "ada_class\n",
      "Training Score: 0.7648980222472964\n",
      "Testing Score: 0.7616032546413019 \n",
      "\n",
      "F1 Score: 0.6633970295655393 \n",
      "\n",
      "xg_class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/craigstrong/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8126766801662845\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37'] ['Age', 'CustomerLifetimeSpend', 'Customer3YearSpend', 'ThreeYearVisitCount', 'SkiLoyaltyIndexRating', 'FrontRangeMarket', 'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012', 'Spend_Winter_2013', 'Spend_Winter_2014', 'Household3YearSpend', 'HouseholdLifetimeSpend', 'NumberOfHouseholdMembers', 'NumberOfAdults', 'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011', 'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014', 'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015', 'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15', 'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', 'Ski_Resort1_2014_2015', 'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']\nexpected f34, f19, f3, f31, f0, f14, f35, f17, f8, f15, f2, f22, f25, f16, f26, f18, f32, f11, f27, f23, f7, f12, f24, f6, f9, f29, f21, f10, f33, f4, f5, f20, f36, f1, f13, f28, f37, f30 in input data\ntraining data did not have the following fields: November_14, CustomerLifetimeSpend, Ski_Resort4_2014_2015, Total_Days_13_14, FrontRangeMarket, Pass_Winter_2014, February_15, Late_Purchase_2014_2015, Pass_Winter_2012, NumberOfAdults, Spend_Winter_2010, Spend_Winter_2012, ThreeYearVisitCount, Ski_Resort2_2014_2015, Pass_Winter_2013, Ski_Resort5_2014_2015, SkiLoyaltyIndexRating, Pass_Winter_2011, Age, Spend_Winter_2013, April_15, Customer3YearSpend, Early_Purchase_2014_2015, Regular_Purchase_2014_2015, December_14, Ski_Resort1_2014_2015, Spend_Winter_2011, NumberOfChildren, March_15, HouseholdLifetimeSpend, Spend_Winter_2014, NumberOfHouseholdMembers, Pass_Winter_2010, Total_Days_14_15, Super_Late_Purchase_2014_2015, Ski_Resort3_2014_2015, Household3YearSpend, January_15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    600\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    601\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0mcolumn_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1477\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37'] ['Age', 'CustomerLifetimeSpend', 'Customer3YearSpend', 'ThreeYearVisitCount', 'SkiLoyaltyIndexRating', 'FrontRangeMarket', 'Spend_Winter_2010', 'Spend_Winter_2011', 'Spend_Winter_2012', 'Spend_Winter_2013', 'Spend_Winter_2014', 'Household3YearSpend', 'HouseholdLifetimeSpend', 'NumberOfHouseholdMembers', 'NumberOfAdults', 'NumberOfChildren', 'Pass_Winter_2010', 'Pass_Winter_2011', 'Pass_Winter_2012', 'Pass_Winter_2013', 'Pass_Winter_2014', 'Early_Purchase_2014_2015', 'Regular_Purchase_2014_2015', 'Late_Purchase_2014_2015', 'Super_Late_Purchase_2014_2015', 'January_15', 'February_15', 'March_15', 'April_15', 'November_14', 'December_14', 'Total_Days_14_15', 'Total_Days_13_14', 'Ski_Resort1_2014_2015', 'Ski_Resort2_2014_2015', 'Ski_Resort3_2014_2015', 'Ski_Resort4_2014_2015', 'Ski_Resort5_2014_2015']\nexpected f34, f19, f3, f31, f0, f14, f35, f17, f8, f15, f2, f22, f25, f16, f26, f18, f32, f11, f27, f23, f7, f12, f24, f6, f9, f29, f21, f10, f33, f4, f5, f20, f36, f1, f13, f28, f37, f30 in input data\ntraining data did not have the following fields: November_14, CustomerLifetimeSpend, Ski_Resort4_2014_2015, Total_Days_13_14, FrontRangeMarket, Pass_Winter_2014, February_15, Late_Purchase_2014_2015, Pass_Winter_2012, NumberOfAdults, Spend_Winter_2010, Spend_Winter_2012, ThreeYearVisitCount, Ski_Resort2_2014_2015, Pass_Winter_2013, Ski_Resort5_2014_2015, SkiLoyaltyIndexRating, Pass_Winter_2011, Age, Spend_Winter_2013, April_15, Customer3YearSpend, Early_Purchase_2014_2015, Regular_Purchase_2014_2015, December_14, Ski_Resort1_2014_2015, Spend_Winter_2011, NumberOfChildren, March_15, HouseholdLifetimeSpend, Spend_Winter_2014, NumberOfHouseholdMembers, Pass_Winter_2010, Total_Days_14_15, Super_Late_Purchase_2014_2015, Ski_Resort3_2014_2015, Household3YearSpend, January_15"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimators = [\n",
    "              ('log_reg', LogisticRegression()),\n",
    "              #('knn_class', KNeighborsClassifier()),\n",
    "              ('dt_class', DecisionTreeClassifier()),\n",
    "              ('bag_class', BaggingClassifier()),\n",
    "              ('rf_class', RandomForestClassifier()),\n",
    "              ('ada_class', AdaBoostClassifier()),\n",
    "              ('xg_class', XGBClassifier()),\n",
    "              ('nueral_net', MLPClassifier(alpha=1))\n",
    "              #('svc', SVC())\n",
    "             ]\n",
    "\n",
    "for estimator in estimators:\n",
    "    pipe = Pipeline([estimator])\n",
    "    print(estimator[0])\n",
    "    print('Training Score: {}'.format(cross_val_score(pipe, X_train_s, y_train).mean()))\n",
    "    pipe.fit(X_train_s, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    print('Testing Score: {}'.format(pipe.score(X_test_s, y_test)), '\\n')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, y_hat)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "              ('nueral_net', MLPClassifier(alpha=1))\n",
    "             ]\n",
    "\n",
    "for estimator in estimators:\n",
    "    pipe = Pipeline([estimator])\n",
    "    print(estimator[0])\n",
    "    print('Training Score: {}'.format(cross_val_score(pipe, X_train, y_train).mean()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    print('Testing Score: {}'.format(pipe.score(X_test, y_test)), '\\n')\n",
    "    print('F1 Score: {}'.format(f1_score(y_test, y_hat)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
